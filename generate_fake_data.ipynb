{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved as 'dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Initialize Faker for generating realistic data\n",
    "fake = Faker()\n",
    "\n",
    "# Predefined phrases for realistic data\n",
    "incident_summaries = [\n",
    "    'Server outage caused by network failure',\n",
    "    'Database crash due to hardware issue',\n",
    "    'High latency observed during peak hours',\n",
    "    'User login issues reported',\n",
    "    'Email service outage due to spam filter issue',\n",
    "    'Network congestion leading to slow internet',\n",
    "    'Disk failure on primary database server',\n",
    "    'Power outage affecting data center operations',\n",
    "    'Software bug causing intermittent crashes',\n",
    "    'Security breach detected in user accounts',\n",
    "    'API response times increased during peak hours',\n",
    "    'Memory leak in application server'\n",
    "]\n",
    "resolution_texts = [\n",
    "    'Rebooted server and reset network configurations',\n",
    "    'Replaced faulty hardware components',\n",
    "    'Scaled up resources to handle peak traffic',\n",
    "    'Fixed user authentication service',\n",
    "    'Adjusted spam filter settings and restored service',\n",
    "    'Optimized network traffic routing and cleared congestion',\n",
    "    'Replaced faulty disk and restored database from backup',\n",
    "    'Restored power and restarted affected systems',\n",
    "    'Patched software to fix the bug',\n",
    "    'Secured user accounts and investigated breach',\n",
    "    'Scaled up API servers to handle increased load',\n",
    "    'Fixed memory leak and restarted application server'\n",
    "]\n",
    "root_causes = [\n",
    "    'Network failure',\n",
    "    'Hardware issue',\n",
    "    'Resource bottleneck',\n",
    "    'Authentication service bug',\n",
    "    'Spam filter issue',\n",
    "    'Network congestion',\n",
    "    'Disk failure',\n",
    "    'Power outage',\n",
    "    'Software bug',\n",
    "    'Security breach',\n",
    "    'High traffic',\n",
    "    'Memory leak'\n",
    "]\n",
    "departments = ['IT', 'Ops', 'DevOps', 'Security']\n",
    "platform_types = ['Cloud', 'Hardware', 'Web', 'Database']\n",
    "\n",
    "# Generate dataset with 100 records\n",
    "data = {\n",
    "    'IncidentSummary': [random.choice(incident_summaries) for _ in range(100)],\n",
    "    'ResolutionText': [random.choice(resolution_texts) for _ in range(100)],\n",
    "    'RootCause': [random.choice(root_causes) for _ in range(100)],\n",
    "    'HoursOfDowntime': np.random.normal(4, 2, 100).round(2),  # Shift mean to make downtime more realistic\n",
    "    'OverallSeverity': np.random.choice(['low', 'medium', 'high', 'critical'], 100),\n",
    "    'Department': np.random.choice(departments, 100),\n",
    "    'PlatformType': np.random.choice(platform_types, 100),\n",
    "    'CompanyAccountability': np.random.choice(['Yes', 'No'], 100)\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Introduce some outliers\n",
    "outlier_indices = np.random.choice(df.index, size=5, replace=False)\n",
    "df.loc[outlier_indices, 'HoursOfDowntime'] *= 3\n",
    "\n",
    "# Ensure that some relationships are not immediately obvious\n",
    "for i in range(len(df)):\n",
    "    if df.loc[i, 'OverallSeverity'] == 4:  # Critical severity\n",
    "        df.loc[i, 'HoursOfDowntime'] += np.random.uniform(1, 5)\n",
    "    elif df.loc[i, 'OverallSeverity'] == 1:  # Low severity\n",
    "        df.loc[i, 'HoursOfDowntime'] -= np.random.uniform(0.5, 2)\n",
    "    else:  # Medium and High severity\n",
    "        df.loc[i, 'HoursOfDowntime'] += np.random.uniform(-1, 3)\n",
    "\n",
    "# Convert categorical variables to numerical\n",
    "df['OverallSeverity'] = df['OverallSeverity'].map({'low': 1, 'medium': 2, 'high': 3, 'critical': 4})\n",
    "df['CompanyAccountability'] = df['CompanyAccountability'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Perform one-hot encoding on 'Department' and 'PlatformType'\n",
    "df = pd.get_dummies(df, columns=['Department', 'PlatformType'])\n",
    "\n",
    "# Generate random timestamps over three months\n",
    "start_date = datetime.now() - timedelta(days=90)\n",
    "timestamps = [start_date + timedelta(days=random.randint(0, 90)) for _ in range(100)]\n",
    "df['Timestamp'] = timestamps\n",
    "\n",
    "# Introduce a correlation between Timestamps and HoursOfDowntime\n",
    "df = df.sort_values('Timestamp').reset_index(drop=True)\n",
    "df['HoursOfDowntime'] = df['HoursOfDowntime'] + np.linspace(0, 5, num=len(df))\n",
    "\n",
    "# Shuffle DataFrame to randomize timestamp order\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('dataset.csv', index=False)\n",
    "\n",
    "print(\"Dataset saved as 'dataset.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
